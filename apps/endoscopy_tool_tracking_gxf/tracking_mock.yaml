%YAML 1.2
# Copyright (c) 2022, NVIDIA CORPORATION.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
name: source
components:
  - name: signal
    type: nvidia::gxf::DoubleBufferTransmitter
  - type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
    parameters:
      transmitter: signal
      min_size: 1
  - name: pool
    type: nvidia::gxf::UnboundedAllocator
  - type: nvidia::holoscan::mocks::VideoBufferMock
    parameters:
      out: signal
      in_width: 1920
      in_height: 1080
      in_channels: 4
      in_bytes_per_pixel: 1
      pool: pool
---
name: broadcast
components:
  - name: input
    type: nvidia::gxf::DoubleBufferReceiver
  - name: output_1
    type: nvidia::gxf::DoubleBufferTransmitter
  - name: output_2
    type: nvidia::gxf::DoubleBufferTransmitter
  - name: output_3
    type: nvidia::gxf::DoubleBufferTransmitter
  - type: nvidia::gxf::Broadcast
    parameters:
      source: input
  - type: nvidia::gxf::MessageAvailableSchedulingTerm
    parameters:
      receiver: input
      min_size: 1
  - type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
    parameters:
      transmitter: output_1
      min_size: 1
  - type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
    parameters:
      transmitter: output_2
      min_size: 1
  - type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
    parameters:
      transmitter: output_3
      min_size: 1
---
name: recorder_format_converter
components:
  - name: in_tensor
    type: nvidia::gxf::DoubleBufferReceiver
  - type: nvidia::gxf::MessageAvailableSchedulingTerm
    parameters:
      receiver: in_tensor
      min_size: 1
  - name: out_tensor
    type: nvidia::gxf::DoubleBufferTransmitter
  - type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
    parameters:
      transmitter: out_tensor
      min_size: 1
  - name: pool
    type: nvidia::gxf::BlockMemoryPool
    parameters:
      storage_type: 1
      block_size: 33177600 # 1920 * 1080 * 4 (channel) * 4 (bytes per pixel)
      num_blocks: 3
  - type: nvidia::holoscan::formatconverter::FormatConverter
    parameters:
      in: in_tensor
      in_dtype: "rgba8888"
      out: out_tensor
      out_dtype: "rgb888"
      pool: pool
---
name: recorder
components:
  - name: input
    type: nvidia::gxf::DoubleBufferReceiver
  - name: allocator
    type: nvidia::gxf::UnboundedAllocator
  - name: component_serializer
    type: nvidia::gxf::StdComponentSerializer
    parameters:
      allocator: allocator
  - name: entity_serializer
    type: nvidia::gxf::StdEntitySerializer
    parameters:
      component_serializers: [component_serializer]
  - type: nvidia::gxf::EntityRecorder
    parameters:
      receiver: input
      entity_serializer: entity_serializer
      directory: "/tmp"
      basename: "tensor"
  - type: nvidia::gxf::MessageAvailableSchedulingTerm
    parameters:
      receiver: input
      min_size: 1
---
name: format_converter
components:
  - name: in_tensor
    type: nvidia::gxf::DoubleBufferReceiver
  - type: nvidia::gxf::MessageAvailableSchedulingTerm
    parameters:
      receiver: in_tensor
      min_size: 1
  - name: out_tensor
    type: nvidia::gxf::DoubleBufferTransmitter
  - type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
    parameters:
      transmitter: out_tensor
      min_size: 1
  - name: pool
    type: nvidia::gxf::BlockMemoryPool
    parameters:
      storage_type: 1
      block_size: 33177600 # 1920 * 1080 * 4 (channel) * 4 (bytes per pixel)
      num_blocks: 3
  - type: nvidia::holoscan::formatconverter::FormatConverter
    parameters:
      in: in_tensor
      in_dtype: "rgba8888"
      out: out_tensor
      out_tensor_name: source_video
      out_dtype: "float32"
      scale_min: 0.0
      scale_max: 255.0
      resize_width: 854
      resize_height: 480
      pool: pool
---
name: lstm_inference
components:
  - name: in_tensor
    type: nvidia::gxf::DoubleBufferReceiver
    parameters:
      capacity: 1
  - name: out_tensor
    type: nvidia::gxf::DoubleBufferTransmitter
  - type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
    parameters:
      transmitter: out_tensor
      min_size: 1
  - type: nvidia::gxf::MessageAvailableSchedulingTerm
    parameters:
      receiver: in_tensor
      min_size: 1
  - name: pool
    type: nvidia::gxf::UnboundedAllocator
  - type: nvidia::holoscan::custom_lstm_inference::TensorRtInference
    parameters:
      model_file_path: /workspace/test_data/endoscopy/model/tool_loc_convlstm.onnx
      engine_cache_dir: /workspace/test_data/endoscopy/model/tool_loc_convlstm_engines
      input_tensor_names:
        - source_video
        - cellstate_in
        - hiddenstate_in
      input_state_tensor_names:
        - cellstate_in
        - hiddenstate_in
      input_binding_names:
        - data_ph:0 # (shape=[1, 480, 854, 3], dtype=float32) <==> source_video
        - cellstate_ph:0 # (shape=[1, 60, 107, 7], dtype=float32) == internal state
        - hiddenstate_ph:0 # (shape=[1, 60, 107, 7], dtype=float32) == internal state
      output_tensor_names:
        - cellstate_out
        - hiddenstate_out
        - probs
        - scaled_coords
        - binary_masks
      output_state_tensor_names:
        - cellstate_out
        - hiddenstate_out
      output_binding_names:
        - Model/net_states:0 # (shape=[ 1, 60, 107, 7], dtype=float32)
        - Model/net_hidden:0 # (shape=[ 1, 60, 107, 7], dtype=float32)
        - probs:0 # (shape=[1, 7], dtype=float32)
        - Localize/scaled_coords:0 # (shape=[1, 7, 2], dtype=float32)
        - Localize_1/binary_masks:0 # (shape=[1, 7, 60, 107], dtype=float32)
      pool: pool
      cuda_stream_pool: utils/cuda_stream
      rx: [in_tensor]
      tx: out_tensor
      force_engine_update: false
      verbose: true
      max_workspace_size: 2147483648
      enable_fp16_: true
---
name: visualizer_format_converter
components:
  - name: in
    type: nvidia::gxf::DoubleBufferReceiver
  - type: nvidia::gxf::MessageAvailableSchedulingTerm
    parameters:
      receiver: in
      min_size: 1
  - name: out
    type: nvidia::gxf::DoubleBufferTransmitter
  - type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
    parameters:
      transmitter: out
      min_size: 1
  - name: pool
    type: nvidia::gxf::BlockMemoryPool
    parameters:
      storage_type: 1
      block_size: 33177600 # 1920 * 1080 * 4 (channel) * 4 (bytes per pixel)
      num_blocks: 2
  - type: nvidia::holoscan::formatconverter::FormatConverter
    parameters:
      in: in
      in_dtype: "rgba8888"
      out: out
      out_dtype: "rgba8888"
      resize_width: 854
      resize_height: 480
      pool: pool
---
name: visualizer
components:
  - name: source_video
    type: nvidia::gxf::DoubleBufferReceiver
  - type: nvidia::gxf::MessageAvailableSchedulingTerm
    parameters:
      receiver: tensor
      min_size: 1
  - name: tensor
    type: nvidia::gxf::DoubleBufferReceiver
  - type: nvidia::gxf::MessageAvailableSchedulingTerm
    parameters:
      receiver: tensor
      min_size: 1
  - name: pool
    type: nvidia::gxf::UnboundedAllocator
  - name: boolean_scheduling_term
    type: nvidia::gxf::BooleanSchedulingTerm
  - type: nvidia::holoscan::visualizer_tool_tracking::Sink
    parameters:
      window_close_scheduling_term: boolean_scheduling_term
      videoframe_vertex_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/viewport_filling_triangle.vert
      videoframe_fragment_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/video_frame.frag
      tooltip_vertex_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/instrument_tip.vert
      tooltip_fragment_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/instrument_tip.frag
      overlay_img_vertex_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/viewport_filling_triangle.vert
      overlay_img_fragment_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/instrument_mask.frag
      overlay_img_width : 107
      overlay_img_height : 60
      overlay_img_channels : 1
      overlay_img_layers : 7
      num_tool_classes: 7
      num_tool_pos_components: 2
      # tool_labels:
      #   - Grasper
      #   - Bipolar
      #   - Hook
      #   - Scissors
      #   - Clipper
      #   - Irrigator
      #   - Spec.Bag
      label_sans_font_path: gxf_extensions/visualizer_tool_tracking/fonts/Roboto-Regular.ttf
      label_sans_bold_font_path: gxf_extensions/visualizer_tool_tracking/fonts/Roboto-Bold.ttf
      in:
        - source_video
        - tensor
      in_tensor_names:
        - ""
        - probs
        - net_states
        - binary_masks
        - scaled_coords
      in_width: 854
      in_height: 480
      in_channels: 4
      in_bytes_per_pixel: 1
      pool: pool
---
components:
  - type: nvidia::gxf::Connection
    parameters:
      source: source/signal
      target: broadcast/input
---
components:
  - type: nvidia::gxf::Connection
    parameters:
      source: broadcast/output_1
      target: format_converter/in_tensor
---
components:
  - type: nvidia::gxf::Connection
    parameters:
      source: broadcast/output_2
      target: recorder_format_converter/in_tensor
---
components:
  - type: nvidia::gxf::Connection
    parameters:
      source: recorder_format_converter/out_tensor
      target: recorder/input
---
components:
  - type: nvidia::gxf::Connection
    parameters:
      source: broadcast/output_3
      target: visualizer_format_converter/in
---
components:
  - type: nvidia::gxf::Connection
    parameters:
      source: visualizer_format_converter/out
      target: visualizer/source_video
---
components:
  - type: nvidia::gxf::Connection
    parameters:
      source: format_converter/out_tensor
      target: lstm_inference/in_tensor
---
components:
  - type: nvidia::gxf::Connection
    parameters:
      source: lstm_inference/out_tensor
      target: visualizer/tensor
---
name: utils
components:
  - name: rt_clock
    type: nvidia::gxf::RealtimeClock
  - type: nvidia::gxf::GreedyScheduler
    parameters:
      clock: rt_clock
      max_duration_ms: 1000000
  - name: cuda_stream
    type: nvidia::gxf::CudaStreamPool
    parameters:
      dev_id: 0
      stream_flags: 0
      stream_priority: 0
      reserved_size: 1
      max_size: 5
  - type: nvidia::gxf::JobStatistics
    parameters:
      clock: rt_clock
