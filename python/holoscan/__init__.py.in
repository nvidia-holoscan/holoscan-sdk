"""
SPDX-FileCopyrightText: Copyright (c) 2022-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""  # noqa: E501

# Check if both holoscan-cuda12 and holoscan-cuda13 are installed
import importlib.util
import warnings

# We import core and gxf to make sure they're available before other modules that rely on them
# We also alias the eagerly-loaded modules so that Python's import system knows that
# `holoscan.core` and `holoscan_cuda12.core` (for example) are the same module.
from . import core, gxf


def _set_version():
    try:
        import importlib.metadata
        return importlib.metadata.version(__name__)
    except ImportError:
        return "@holoscan_VERSION@" or "unknown version"


__version__ = _set_version()


# Check if both holoscan-cuda12 and holoscan-cuda13 are installed
_cuda12_installed = importlib.util.find_spec("holoscan_cuda12") is not None
_cuda13_installed = importlib.util.find_spec("holoscan_cuda13") is not None
if _cuda12_installed and _cuda13_installed:
    import importlib.metadata
    import sys
    pkg_name = importlib.metadata.distribution(__name__).metadata["Name"]
    module_path = sys.modules[__name__].__file__
    warnings.warn(
        "Both holoscan-cuda12 and holoscan-cuda13 are installed. "
        f"Currently importing {pkg_name} from {module_path}.",
        # "To use a specific version, import it directly, e.g., "
        # "`import holoscan_cuda12 as holoscan`",
        UserWarning,
        stacklevel=2,
    )

# Define as_tensor
def as_tensor(obj):
    if hasattr(obj, "__cuda_array_interface__") or hasattr(obj, "__array_interface__"):
        # Workaround for bug in CuPy<13.0.0a1 where strides of ndarray with all but 1 dimension a
        # singleton, could become order='F' strides instead of the expected order='C' strides.
        # See:
        #   https://github.com/cupy/cupy/pull/7438
        #   https://github.com/cupy/cupy/pull/7457
        #   https://forums.developer.nvidia.com/t/known-issue-in-cupy-affecting-tensor-interop/244423
        #
        # Here we force any array that is both C and F contiguous to have C-ordered strides
        # We do this for both NumPy and CuPy arrays for consistency.

        # nd-array, but with only 1 non-singleton dimension
        nd_singleton = (obj.ndim > 1) and (sum(tuple(s > 1 for s in obj.shape)) == 1)

        # hasattr checks exclude PyTorch Tensors from this code path (they don't have a flags
        # attribute)
        if nd_singleton and hasattr(obj, "flags") and hasattr(obj.flags, "forc") and obj.flags.forc:
            # determine expected strides for a C-contiguous array
            expected_strides = [
                1,
            ] * obj.ndim
            expected_strides[obj.ndim - 1] = obj.itemsize
            for i in range(obj.ndim - 2, -1, -1):
                expected_strides[i] = expected_strides[i + 1] * obj.shape[i + 1]
            expected_strides = tuple(expected_strides)

            # make a copy to force stride update if they do not match
            if obj.strides != expected_strides:
                if hasattr(obj, "__cuda_array_interface__"):
                    try:
                        import cupy as cp

                        if isinstance(obj, cp.ndarray):
                            # use as_strided to avoid a copy
                            obj = cp.lib.stride_tricks.as_strided(
                                obj, shape=obj.shape, strides=expected_strides
                            )
                            return core.Tensor.as_tensor(obj)
                    except ImportError:
                        pass
                elif hasattr(obj, "__array_interface__"):
                    try:
                        import numpy as np

                        if isinstance(obj, np.ndarray):
                            # use as_strided to avoid a copy
                            obj = np.lib.stride_tricks.as_strided(
                                obj, shape=obj.shape, strides=expected_strides
                            )
                            return core.Tensor.as_tensor(obj)
                    except ImportError:
                        pass
                # update strides by making an explicit copy
                try:
                    obj = obj.copy(order="C")
                except (AttributeError, TypeError):
                    import warnings

                    warnings.warn(
                        "Unexpected strides encountered during call to `as_tensor` and no copy "
                        "method was available. Leaving the strides unchanged.",
                        stacklevel=2,
                    )

    return core.Tensor.as_tensor(obj)


as_tensor.__doc__ = core.Tensor.as_tensor.__doc__

# Other modules are exposed to the public API but will only be lazily loaded
_EXTRA_MODULES = [
    "conditions",
    "data_loggers",
    "decorator",
    "executors",
    "graphs",
    "logger",
    "operators",
    "pose_tree",
    "resources",
    "schedulers",
]

# Define __all__
__all__ = ["__version__", "as_tensor", "core", "gxf"] + _EXTRA_MODULES


# Autocomplete
def __dir__():
    return __all__


# Lazily load extra modules
def __getattr__(attr):
    from importlib import import_module

    if attr in _EXTRA_MODULES:
        module = import_module(f"{__name__}.{attr}")
        globals()[attr] = module  # cache for __getattr__
        return module

    raise AttributeError(f"module {__name__} has no attribute {attr}")
